import torch
from torch import nn
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets
import torchvision
from torch.nn import Conv2d, Linear, Flatten, Sequential, L1Loss, MSELoss,CrossEntropyLoss
from torch.nn import MaxPool2d
from torch.nn import ReLU
from torch.nn import Dropout

from torch.nn import functional as F

class Inception(nn.Module):
    # c1--c4是每条路径的输出通道数
    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):#除c1外,c2,c3,c4都有两层
        super(Inception, self).__init__(**kwargs)

        # 线路1，单1x1卷积层
        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)

        # 线路2，1x1卷积层后接3x3卷积层
        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)
        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)

        # 线路3，1x1卷积层后接5x5卷积层
        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)
        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)

        # 线路4，3x3最大汇聚层后接1x1卷积层
        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)

    def forward(self, x):

        p1 = F.relu(self.p1_1(x))
        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
        p4 = F.relu(self.p4_2(self.p4_1(x)))

        # 在通道维度上连结输出
        return torch.cat((p1, p2, p3, p4), dim=1)

b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))#高宽减半

b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),
                   nn.ReLU(),
                   nn.Conv2d(64, 192, kernel_size=3, padding=1),
                   nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))#高宽减半

b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),
                   Inception(256, 128, (128, 192), (32, 96), 64),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))#高宽减半

b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),
                   Inception(512, 160, (112, 224), (24, 64), 64),
                   Inception(512, 128, (128, 256), (24, 64), 64),
                   Inception(512, 112, (144, 288), (32, 64), 64),
                   Inception(528, 256, (160, 320), (32, 128), 128),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))#高宽减半

b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),
                   Inception(832, 384, (192, 384), (48, 128), 128),
                   nn.AdaptiveAvgPool2d((1,1)),#通道数当类别数
                   nn.Flatten())

net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))
writer=SummaryWriter('test')#可视化

train_data=datasets.MNIST('./data',train=True,transform=torchvision.transforms.ToTensor(),download=True)#train_dataset_size=50000
test_data=datasets.MNIST('./data',train=False,transform=torchvision.transforms.ToTensor(),download=True)#test_dataset_size=10000
train_dataloader=DataLoader(train_data,batch_size=128)
test_dataloader=DataLoader(test_data,batch_size=128)

train_dataset_size=len(train_data)
test_dataset_size=len(test_data)
print(train_dataset_size)
print(test_dataset_size)

device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')


net=net.to(device)

loss_fn=nn.CrossEntropyLoss()#损失函数实例化
loss_fn=loss_fn.to(device)

learning_rate=0.9#学习率
optimizer=torch.optim.SGD(net.parameters(),lr=learning_rate)#优化器实例化

total_train_step=0
total_test_step=0

epoch=30
for i in range(epoch):
    print('-------第{}轮-------'.format(i+1))
    total_train_loss=0
    for data in train_dataloader:
        imgs,targets=data
        imgs=imgs.to(device)
        targets=targets.to(device)
        output=net(imgs)
        loss=loss_fn(output,targets)
        total_train_loss+=loss
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_train_step+=1
        if total_train_step%100==0:
            writer.add_scalar('tain',total_train_loss.item(),total_train_step)
        #print('损失',loss)
    print(total_train_loss)
    score=0
    accuracy=0
    total_test_loss=0
    with torch.no_grad():
        for data in test_dataloader:
            imgs, targets = data
            imgs = imgs.to(device)
            targets = targets.to(device)
            output = net(imgs)
            loss = loss_fn(output, targets)
            total_test_loss+=loss
            total_test_step+=1
            score+=(output.argmax(1)==targets).sum()
        accuracy=score/test_dataset_size
        writer.add_scalar('test',total_test_loss.item(),total_test_step)
        #torch.save('net{}.pth'.format(i))
        print(total_test_loss)
        print('accuracy:',accuracy)