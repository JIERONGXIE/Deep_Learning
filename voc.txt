import os
from PIL import Image
import matplotlib.pyplot as plt
from torchvision import transforms
import torch
import numpy as np



def read_path(root, is_train=True):
    txt_fname = root + '/ImageSets/Segmentation/' + ('train.txt' if is_train else 'val.txt')
    with open(txt_fname, 'r') as f:
        filenames = f.read().split()
    images_path = [os.path.join(root, 'JPEGImages', i + '.jpg') for i in filenames]
    labels_path = [os.path.join(root, 'SegmentationClass', i + '.png') for i in filenames]
    return images_path, labels_path#都是一维list,元素是路径

dataset_path=r'G:\voc\VOC2012'

def rand_crop(image, label, height, width):#数据预处理
    i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(height, width))
    image = transforms.functional.crop(image, i, j, h, w)
    label = transforms.functional.crop(label, i, j, h, w)
    return image, label

VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],
                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],
                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],
                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],
                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],
                [0, 64, 128]]

VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',
               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
               'diningtable', 'dog', 'horse', 'motorbike', 'person',
               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']

# images, labels = read_file_list(dataset_path, True)
# img = Image.open(images[0]).convert('RGB')
# label = Image.open(labels[0]).convert('RGB')
# plt.subplot(121), plt.imshow(img)
# plt.subplot(122), plt.imshow(label)
# plt.show()

colormap2label = torch.zeros(256 ** 3, dtype=torch.uint8)
for i, colormap in enumerate(VOC_COLORMAP):
    colormap2label[(colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i

def label_indices(colormap):
    colormap = np.array(colormap).astype('int32')
    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256
           + colormap[:, :, 2])
    return colormap2label[idx]

class VOCDataset(torch.utils.data.Dataset):
    def __init__(self, is_train, crop_size, voc_root):

        #crop_size: (h, w)

        self.mean = np.array([0.485, 0.456, 0.406])
        self.std = np.array([0.229, 0.224, 0.225])

        self.transf = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=self.mean, std=self.std)
        ])

        self.crop_size = crop_size

        images_path, labels_path = read_path(root=voc_root, is_train=is_train)
        self.images_path = self.filter(images_path)  # images list
        self.labels_path = self.filter(labels_path)  # labels list
        print('Read ' + str(len(self.images)) + ' valid examples')

    def filter(self, imgs):  # 过滤掉尺寸小于crop_size的图片
        return [img for img in imgs if (
                Image.open(img).size[1] >= self.crop_size[0] and
                Image.open(img).size[0] >= self.crop_size[1])]

    def __getitem__(self, index):
        image = self.images_path[index]
        label = self.labels_path[index]
        image = Image.open(image).convert('RGB')
        label = Image.open(label).convert('RGB')

        image, label = rand_crop(image, label,
                                     *self.crop_size)
        image = self.transf(image)
        label = label_indices(label)

        return image, label#float32 tensor, uint8 tensor

    def __len__(self):
        return len(self.images)